{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6558c49a-6c79-4605-afb3-556902785def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b79378f8-df53-4d32-a060-12b3d618dc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake News NaN Counts:\n",
      "title_text    0\n",
      "text          0\n",
      "label         0\n",
      "url           0\n",
      "image_path    0\n",
      "dtype: int64\n",
      "Fake News Label Distribution:\n",
      "label\n",
      "0    23481\n",
      "Name: count, dtype: int64\n",
      "Fake News Columns: ['title_text', 'text', 'label', 'url', 'image_path']\n",
      "Fake News Preview:\n",
      "                                          title_text  \\\n",
      "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
      "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
      "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
      "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
      "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
      "\n",
      "                                                text  label  \\\n",
      "0  Donald Trump just couldn t wish all Americans ...      0   \n",
      "1  House Intelligence Committee Chairman Devin Nu...      0   \n",
      "2  On Friday, it was revealed that former Milwauk...      0   \n",
      "3  On Christmas day, Donald Trump announced that ...      0   \n",
      "4  Pope Francis used his annual Christmas Day mes...      0   \n",
      "\n",
      "                             url                   image_path  \n",
      "0  http://fake-site.com/article0  images/fake_placeholder.jpg  \n",
      "1  http://fake-site.com/article1  images/fake_placeholder.jpg  \n",
      "2  http://fake-site.com/article2  images/fake_placeholder.jpg  \n",
      "3  http://fake-site.com/article3  images/fake_placeholder.jpg  \n",
      "4  http://fake-site.com/article4  images/fake_placeholder.jpg  \n"
     ]
    }
   ],
   "source": [
    "# Load Fake.csv\n",
    "fake_df = pd.read_csv('Fake.csv')\n",
    "\n",
    "# Add label column explicitly\n",
    "fake_df['label'] = 0  # Fake = 0\n",
    "\n",
    "# Select relevant columns, ensuring 'label' is included\n",
    "fake_df = fake_df[['title', 'text', 'label']].copy()\n",
    "\n",
    "# Add placeholders\n",
    "fake_df['url'] = 'http://fake-site.com/article' + fake_df.index.astype(str)\n",
    "fake_df['image_path'] = 'images/fake_placeholder.jpg'\n",
    "fake_df.rename(columns={'title': 'title_text'}, inplace=True)\n",
    "\n",
    "# Check for NaN and drop\n",
    "print(\"Fake News NaN Counts:\")\n",
    "print(fake_df.isnull().sum())\n",
    "fake_df = fake_df.dropna(subset=['title_text', 'text'])  # Drop NaN text rows\n",
    "\n",
    "# Verify labels\n",
    "print(\"Fake News Label Distribution:\")\n",
    "print(fake_df['label'].value_counts())\n",
    "print(\"Fake News Columns:\", fake_df.columns.tolist())\n",
    "print(\"Fake News Preview:\")\n",
    "print(fake_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c844c95-dd2a-48be-8aa4-c78717215750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real News NaN Counts:\n",
      "title_text    0\n",
      "text          0\n",
      "label         0\n",
      "url           0\n",
      "image_path    0\n",
      "dtype: int64\n",
      "Real News Label Distribution:\n",
      "label\n",
      "1    44898\n",
      "Name: count, dtype: int64\n",
      "Real News Columns: ['title_text', 'text', 'label', 'url', 'image_path']\n",
      "Real News Preview:\n",
      "                                          title_text  \\\n",
      "0  As U.S. budget fight looms, Republicans flip t...   \n",
      "1  U.S. military to accept transgender recruits o...   \n",
      "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
      "3  FBI Russia probe helped by Australian diplomat...   \n",
      "4  Trump wants Postal Service to charge 'much mor...   \n",
      "\n",
      "                                                text  label  \\\n",
      "0  WASHINGTON (Reuters) - The head of a conservat...      1   \n",
      "1  WASHINGTON (Reuters) - Transgender people will...      1   \n",
      "2  WASHINGTON (Reuters) - The special counsel inv...      1   \n",
      "3  WASHINGTON (Reuters) - Trump campaign adviser ...      1   \n",
      "4  SEATTLE/WASHINGTON (Reuters) - President Donal...      1   \n",
      "\n",
      "                            url                   image_path  \n",
      "0  https://reuters.com/article0  images/real_placeholder.jpg  \n",
      "1  https://reuters.com/article1  images/real_placeholder.jpg  \n",
      "2  https://reuters.com/article2  images/real_placeholder.jpg  \n",
      "3  https://reuters.com/article3  images/real_placeholder.jpg  \n",
      "4  https://reuters.com/article4  images/real_placeholder.jpg  \n"
     ]
    }
   ],
   "source": [
    "# Load True.csv\n",
    "true_df = pd.read_csv('True.csv')\n",
    "true_df['label'] = 1  # Real = 1\n",
    "\n",
    "# Select relevant columns, including label\n",
    "true_df = true_df[['title', 'text', 'label']].copy()\n",
    "true_df['url'] = 'https://reuters.com/article' + true_df.index.astype(str)\n",
    "true_df['image_path'] = 'images/real_placeholder.jpg'\n",
    "true_df.rename(columns={'title': 'title_text'}, inplace=True)\n",
    "\n",
    "# Load News_Category_Dataset_v3.json\n",
    "news_df = pd.read_json('News_Category_Dataset_v3.json', lines=True)\n",
    "news_df = news_df[['headline', 'short_description', 'link']].head(len(fake_df))\n",
    "news_df['label'] = 1\n",
    "news_df['image_path'] = 'images/real_placeholder.jpg'\n",
    "news_df.rename(columns={'headline': 'title_text', 'short_description': 'text', 'link': 'url'}, inplace=True)\n",
    "\n",
    "# Combine real datasets\n",
    "real_df = pd.concat([true_df, news_df], ignore_index=True)\n",
    "\n",
    "# Check for NaN and drop\n",
    "print(\"Real News NaN Counts:\")\n",
    "print(real_df.isnull().sum())\n",
    "real_df = real_df.dropna(subset=['title_text', 'text'])\n",
    "\n",
    "# Verify labels\n",
    "print(\"Real News Label Distribution:\")\n",
    "print(real_df['label'].value_counts())\n",
    "print(\"Real News Columns:\", real_df.columns.tolist())\n",
    "print(\"Real News Preview:\")\n",
    "print(real_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7146ddb-765c-477b-aaa3-419e2f5e9099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Dataset NaN Counts:\n",
      "title_text    0\n",
      "text          0\n",
      "label         0\n",
      "url           0\n",
      "image_path    0\n",
      "dtype: int64\n",
      "Combined Dataset Label Distribution:\n",
      "label\n",
      "1    44898\n",
      "0    23481\n",
      "Name: count, dtype: int64\n",
      "Combined Dataset Saved as 'combined_news_dataset.csv'!\n",
      "Combined Dataset Preview:\n",
      "                                          title_text  \\\n",
      "0  FIVE REASONS You Should Vote For Donald Trump ...   \n",
      "1  Trump to meet House, Senate tax cut negotiator...   \n",
      "2  UN To Scale Up Humanitarian Operations In Ukra...   \n",
      "3  Rudy Giuliani Reverses Trump Team's Position, ...   \n",
      "4  Doug Jones Says Congress Should 'Move On' From...   \n",
      "\n",
      "                                                text  label  \\\n",
      "0  (LANGUAGE WARNING:) If you re a Donald Trump s...      0   \n",
      "1  WASHINGTON (Reuters) - President Donald Trump ...      1   \n",
      "2  The UN will allocate $20 million to “help with...      1   \n",
      "3  Obstruction of justice charges are reportedly ...      1   \n",
      "4  Earlier this month, Alabama's senator-elect ca...      1   \n",
      "\n",
      "                                                 url  \\\n",
      "0                  http://fake-site.com/article13958   \n",
      "1                     https://reuters.com/article195   \n",
      "2  https://www.huffpost.com/entry/ukraine-russia-...   \n",
      "3  https://www.huffingtonpost.com/entry/giuliani-...   \n",
      "4  https://www.huffingtonpost.com/entry/doug-jone...   \n",
      "\n",
      "                    image_path  \n",
      "0  images/fake_placeholder.jpg  \n",
      "1  images/real_placeholder.jpg  \n",
      "2  images/real_placeholder.jpg  \n",
      "3  images/real_placeholder.jpg  \n",
      "4  images/real_placeholder.jpg  \n",
      "Dataset Size: (68379, 5)\n"
     ]
    }
   ],
   "source": [
    "# Combine fake and real\n",
    "df = pd.concat([fake_df, real_df], ignore_index=True)\n",
    "\n",
    "# Shuffle\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check for NaN and drop\n",
    "print(\"Combined Dataset NaN Counts:\")\n",
    "print(df.isnull().sum())\n",
    "df = df.dropna(subset=['label', 'title_text', 'text'])\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "# Verify labels\n",
    "print(\"Combined Dataset Label Distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "assert len(df['label'].unique()) == 2, \"Only one class found in combined dataset!\"\n",
    "\n",
    "# Save combined dataset\n",
    "df.to_csv('combined_news_dataset.csv', index=False)\n",
    "print(\"Combined Dataset Saved as 'combined_news_dataset.csv'!\")\n",
    "print(\"Combined Dataset Preview:\")\n",
    "print(df.head())\n",
    "print(\"Dataset Size:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d80506ae-baca-4ed7-a9b0-c23af9b13a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Features Shape: (68379, 500)\n"
     ]
    }
   ],
   "source": [
    "# Clean text function\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Combine title and text\n",
    "df['full_text'] = df['title_text'] + ' ' + df['text']\n",
    "df['clean_text'] = df['full_text'].apply(clean_text)\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf = TfidfVectorizer(max_features=500)\n",
    "text_features = tfidf.fit_transform(df['clean_text']).toarray()\n",
    "print(\"Text Features Shape:\", text_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35c741c7-61aa-4835-ad3a-5ef3b1d26768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Features Shape: (68379, 2)\n",
      "URL Features Shape: (68379, 2)\n"
     ]
    }
   ],
   "source": [
    "# Simulate image features\n",
    "image_features = np.array([[2500, 100] if label == 0 else [2500, 150] for label in df['label']])\n",
    "print(\"Image Features Shape:\", image_features.shape)\n",
    "\n",
    "# Extract URL features\n",
    "def extract_url_features(url):\n",
    "    domain = urlparse(str(url)).netloc\n",
    "    is_https = 1 if 'https' in str(url) else 0\n",
    "    return [len(domain), is_https]\n",
    "\n",
    "url_features = np.array([extract_url_features(url) for url in df['url']])\n",
    "print(\"URL Features Shape:\", url_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e81968b1-3d94-495f-bf2f-3a1b709a4c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in y: [0 1]\n",
      "NaN in y: 0\n",
      "Training Features Shape: (47865, 504)\n",
      "Testing Features Shape: (20514, 504)\n",
      "Training Labels Distribution: [16516 31349]\n",
      "Testing Labels Distribution: [ 6965 13549]\n"
     ]
    }
   ],
   "source": [
    "# Combine all features\n",
    "X = np.hstack((text_features, image_features, url_features))\n",
    "y = df['label'].values\n",
    "\n",
    "# Verify classes in y\n",
    "print(\"Classes in y:\", np.unique(y))\n",
    "print(\"NaN in y:\", np.isnan(y).sum())\n",
    "assert len(np.unique(y)) == 2, \"Only one class in y!\"\n",
    "assert not np.isnan(y).any(), \"y contains NaN!\"\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(\"Training Features Shape:\", X_train.shape)\n",
    "print(\"Testing Features Shape:\", X_test.shape)\n",
    "print(\"Training Labels Distribution:\", np.bincount(y_train))\n",
    "print(\"Testing Labels Distribution:\", np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4124db3c-7735-480a-866e-6068cb33b373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model and vectorizer saved as 'my_fake_news_model.pkl' and 'my_tfidf_vectorizer.pkl'!\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save your trained model and vectorizer\n",
    "joblib.dump(model, 'my_fake_news_model.pkl')\n",
    "joblib.dump(tfidf, 'my_tfidf_vectorizer.pkl')\n",
    "print(\"Your model and vectorizer saved as 'my_fake_news_model.pkl' and 'my_tfidf_vectorizer.pkl'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26546388-4fd1-4b47-bff0-f19224fd6869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Your Model:\n",
      "              precision  recall  f1-score  support\n",
      "0                   1.0     1.0       1.0   6965.0\n",
      "1                   1.0     1.0       1.0  13549.0\n",
      "accuracy            1.0     1.0       1.0      1.0\n",
      "macro avg           1.0     1.0       1.0  20514.0\n",
      "weighted avg        1.0     1.0       1.0  20514.0\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(\"Classification Report for Your Model:\")\n",
    "print(pd.DataFrame(report).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f24512f-d77a-421e-a48c-535b945b3090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
